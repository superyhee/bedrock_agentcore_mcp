"""
Boto3 client for calling deployed AgentCore Baidu Map Agent with streaming support

This client demonstrates how to invoke AgentCore Runtime agents with streaming responses.
The streaming approach delivers chunks of data in real-time as the agent processes requests,
providing immediate feedback rather than waiting for the complete response.

Features:
- Streaming response support (text/event-stream)
- Standard JSON response support
- Session management for conversation context
- Real-time output display
- 15+ pre-built conversation scenarios

Available Scenarios (16 total):

Basic Scenario (1):
1. åŸºç¡€åœºæ™¯ - Basic user info and personalized recommendations

ğŸš— Smart Cockpit Scenarios (15) - Optimized for In-Car Use:
2. æ™ºèƒ½å¯¼èˆª - Smart navigation with real-time routing (P0)
3. æ²¿é€”æœåŠ¡ - En-route services (restaurants, gas stations) (P1)
4. åœè½¦åœºæ™¯ - Parking lot search and navigation (P1)
5. è‡ªé©¾æ¸¸ - Road trip planning (P2)
6. æ¥é€äºº - Airport/station pickup scenarios (P2)
7. å……ç”µåŠ æ²¹ - Refueling and EV charging (P1)
8. å®æ—¶è·¯å†µ - Real-time traffic and route optimization (P0)
9. è¯­éŸ³æ§åˆ¶ - Voice command interactions (P2)
10. å¤šç›®çš„åœ° - Multi-destination route planning (P2)
11. å¤©æ°”è·¯å†µ - Weather-aware driving (P3)
12. è½¦è¾†ç»´æŠ¤ - Vehicle maintenance and service (P3)
13. æ–°æ‰‹å¸æœº - Novice driver assistance (P3)
14. å•†åŠ¡å‡ºè¡Œ - Business trip efficiency (P3)
15. å®¶åº­å‡ºæ¸¸ - Family-friendly routes (P3)
16. å¤œé—´é©¾é©¶ - Safe night driving (P3)

Usage:
    # Run with scenario selection
    python clients/boto3_client.py
    
    # Run with custom question
    python clients/boto3_client.py "ä½ çš„é—®é¢˜"
"""
import boto3
import json

# Initialize the bedrock-agentcore client
agent_core_client = boto3.client('bedrock-agentcore', region_name='us-west-2')

# Example questions to test - å¤šåœºæ™¯å¯¹è¯æµ‹è¯•é›†
test_questions = [
    
    # åœºæ™¯1: ç”¨æˆ·ä¿¡æ¯æ”¶é›† + ä¸ªæ€§åŒ–æ¨è
    "æˆ‘å®¶çš„åœ°å€æ˜¯:åŒ—äº¬æµ·æ·€åŒºä¸Šåœ°åè¡—10å·ï¼Œæˆ‘çš„åŠå…¬å®¤åœ¨:åŒ—äº¬æœé˜³åŒºäººå¯¿ä¿é™©å¤§å¦ï¼Œæˆ‘çš„çˆ±å¥½æ˜¯å‡ºé—¨èµèŠ±ï¼Œæˆ‘å–œæ¬¢åƒæµ·é²œ",
    "æˆ‘ä½åœ¨åŒ—äº¬æµ·æ·€åŒºé™„è¿‘ï¼Œæˆ‘æƒ³æ—©ä¸Š8ç‚¹å‡ºé—¨ï¼Œä¸­åˆé¡ºè·¯æ‰¾ä¸ªåœ°æ–¹åƒé¥­ï¼Œä¸‹åˆç»§ç»­ç©ï¼Œå¸®æˆ‘æ ¹æ®æˆ‘çš„çˆ±å¥½è§„åˆ’ä¸€ä¸ªä¸€å¤©æ¸¸ç©çš„è§„åˆ’",
    "å¸®æˆ‘æŸ¥çœ‹è¿™æ¡è·¯çº¿çš„ç›®å‰çš„äº¤é€šçŠ¶å†µï¼Ÿ",
    "æŸ¥è¯¢amazonæœ€æ–°çš„è‚¡ä»·æ˜¯å¤šå°‘"
]

# ========== æ™ºèƒ½åº§èˆ±ä¸“å±åœºæ™¯ ==========

# åœºæ™¯16: æ™ºèƒ½å¯¼èˆªåœºæ™¯ï¼ˆè½¦è½½æ ¸å¿ƒï¼‰
smart_navigation_scenario = [
    "ä»æˆ‘çš„ä½å€å¯¼èˆªåˆ°æˆ‘çš„åŠå…¬å®¤",
    "å‰æ–¹è·¯å†µæ€ä¹ˆæ ·ï¼Ÿ",
    "æœ‰æ²¡æœ‰æ›´å¿«çš„è·¯çº¿é¿å¼€æ‹¥å µï¼Ÿ",
    "é¢„è®¡ä»€ä¹ˆæ—¶å€™åˆ°è¾¾ï¼Ÿ",
    "é€”ä¸­å¸®æˆ‘æ‰¾ä¸ªåŠ æ²¹ç«™",
    "æœ€è¿‘çš„åŠ æ²¹ç«™åœ¨å“ªé‡Œï¼Ÿ",
    "å¯¼èˆªè¿‡å»"
]

# åœºæ™¯17: æ²¿é€”æœåŠ¡åœºæ™¯ï¼ˆè½¦è½½é«˜é¢‘ï¼‰
enroute_service_scenario = [
    "æˆ‘å‡†å¤‡ä»æˆ‘å®¶å»é¦–éƒ½æœºåœº",
    "è·¯ä¸Šæƒ³åƒç‚¹ä¸œè¥¿ï¼Œæ¨èé¡ºè·¯çš„é¤å…",
    "é‚£å®¶åº—æœ‰åœè½¦ä½å—ï¼Ÿ",
    "åœè½¦æ–¹ä¾¿å—ï¼Ÿ",
    "ç°åœ¨è·¯å†µå¦‚ä½•ï¼Ÿ"
]

# åœºæ™¯18: åœè½¦åœºæ™¯ï¼ˆè½¦è½½åˆšéœ€ï¼‰
parking_scenario = [
    "æˆ‘ä»æˆ‘å®¶å»ä¸‰é‡Œå±¯å¤ªå¤é‡Œè´­ç‰©",
    "é‚£é‡Œæœ‰åœè½¦åœºå—ï¼Ÿ",
    "åœè½¦è´¹æ€ä¹ˆæ”¶ï¼Ÿ",
    "ç°åœ¨æœ‰ç©ºä½å—ï¼Ÿ",
    "å¯¼èˆªåˆ°åœè½¦åœºå…¥å£",
    "å¦‚æœé‚£é‡Œåœæ»¡äº†ï¼Œé™„è¿‘è¿˜æœ‰å…¶ä»–åœè½¦åœºå—ï¼Ÿ",
    "å“ªä¸ªæ›´ä¾¿å®œï¼Ÿ"
]

# åœºæ™¯19: è‡ªé©¾æ¸¸åœºæ™¯ï¼ˆå‘¨æœ«é«˜é¢‘ï¼‰
road_trip_scenario = [
    "è¿™ä¸ªå‘¨æœ«æƒ³è‡ªé©¾å»éƒŠåŒºç©ï¼Œæ¨èä¸€ä¸‹åŒ—äº¬å‘¨è¾¹çš„æ™¯ç‚¹",
    "å¤åŒ—æ°´é•‡æ€ä¹ˆæ ·ï¼Ÿ",
    "ä»å¸‚åŒºå¼€è½¦è¿‡å»è¦å¤šä¹…ï¼Ÿ",
    "è·¯ä¸Šæœ‰æœåŠ¡åŒºå—ï¼Ÿ",
    "é‚£è¾¹æœ‰ä»€ä¹ˆå¥½åƒçš„ï¼Ÿ",
    "é™„è¿‘æœ‰ä½å®¿çš„åœ°æ–¹å—ï¼Ÿ",
    "è§„åˆ’ä¸€ä¸ªä¸¤å¤©ä¸€å¤œçš„è‡ªé©¾è·¯çº¿"
]

# åœºæ™¯20: æ¥é€äººåœºæ™¯ï¼ˆæ—¥å¸¸é«˜é¢‘ï¼‰
pickup_scenario = [
    "æˆ‘è¦ä»æˆ‘å®¶å»é¦–éƒ½æœºåœºT3èˆªç«™æ¥¼æ¥äºº",
    "ç°åœ¨å‡ºå‘æ¥å¾—åŠå—ï¼Ÿ",
    "èµ°å“ªæ¡è·¯æœ€å¿«ï¼Ÿ",
    "æœºåœºåœè½¦æ€ä¹ˆæ”¶è´¹ï¼Ÿ",
    "æœ‰å…è´¹ç­‰å¾…æ—¶é—´å—ï¼Ÿ",
    "å¦‚æœèˆªç­å»¶è¯¯äº†ï¼Œé™„è¿‘æœ‰ä»€ä¹ˆåœ°æ–¹å¯ä»¥ç­‰ï¼Ÿ",
    "è¿”ç¨‹çš„æ—¶å€™æƒ³é¡ºè·¯åƒä¸ªé¥­ï¼Œæ¨èä¸€ä¸‹"
]

# åœºæ™¯21: å……ç”µ/åŠ æ²¹åœºæ™¯ï¼ˆè½¦è¾†æœåŠ¡ï¼‰
refuel_scenario = [
    "æ²¹å¿«æ²¡äº†ï¼Œå¸®æˆ‘æ‰¾æœ€è¿‘çš„åŠ æ²¹ç«™",
    "å“ªå®¶æ²¹ä»·ä¾¿å®œï¼Ÿ",
    "å¯¼èˆªåˆ°é‚£ä¸ªåŠ æ²¹ç«™",
    "è¿˜æœ‰å¤šè¿œï¼Ÿ",
    "å¦‚æœæ˜¯ç”µåŠ¨è½¦ï¼Œé™„è¿‘æœ‰å……ç”µæ¡©å—ï¼Ÿ",
    "å……ç”µæ¡©ç°åœ¨æœ‰ç©ºä½å—ï¼Ÿ",
    "å……æ»¡ç”µå¤§æ¦‚éœ€è¦å¤šä¹…ï¼Ÿ"
]

# åœºæ™¯22: å®æ—¶è·¯å†µåœºæ™¯ï¼ˆè½¦è½½æ ¸å¿ƒï¼‰
traffic_scenario = [
    "æŸ¥è¯¢ä¸€ä¸‹å‰æ–¹è·¯å†µ",
    "æœ‰äº‹æ•…å—ï¼Ÿ",
    "æ‹¥å µä¸¥é‡å—ï¼Ÿå¤§æ¦‚å µå¤šä¹…ï¼Ÿ",
    "æ¨èä¸€æ¡é¿å¼€æ‹¥å µçš„è·¯çº¿",
    "æ–°è·¯çº¿ä¼šå¤šèŠ±å¤šå°‘æ—¶é—´ï¼Ÿ",
    "æ²¿é€”æœ‰é™è¡Œå—ï¼Ÿ",
    "ä»Šå¤©æˆ‘çš„è½¦èƒ½è¿›äº”ç¯å—ï¼Ÿ"
]


# åœºæ™¯24: å¤šç›®çš„åœ°åœºæ™¯ï¼ˆå¤æ‚è§„åˆ’ï¼‰
multi_destination_scenario = [
    "æˆ‘ä»Šå¤©è¦å»ä¸‰ä¸ªåœ°æ–¹ï¼šå…ˆå»å…¬å¸ï¼Œç„¶åå»å®¢æˆ·é‚£é‡Œå¼€ä¼šï¼Œæœ€åå»æ¥å­©å­æ”¾å­¦",
    "å¸®æˆ‘è§„åˆ’ä¸€ä¸ªæœ€ä¼˜è·¯çº¿",
    "ç¬¬ä¸€ç«™åˆ°ç¬¬äºŒç«™è¦å¤šä¹…ï¼Ÿ",
    "ä¸­åˆèƒ½åœ¨å®¢æˆ·é™„è¿‘åƒé¥­å—ï¼Ÿæ¨èä¸€ä¸‹",
    "ä¸‹åˆ3ç‚¹å¿…é¡»åˆ°å­¦æ ¡ï¼Œæ¥å¾—åŠå—ï¼Ÿ",
    "å¦‚æœæ¥ä¸åŠï¼Œè°ƒæ•´ä¸€ä¸‹é¡ºåº",
    "å…¨ç¨‹éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ"
]

# åœºæ™¯25: å¤©æ°”è·¯å†µåœºæ™¯ï¼ˆå®‰å…¨é©¾é©¶ï¼‰
weather_driving_scenario = [
    "æŸ¥ä¸€ä¸‹ä»Šå¤©çš„å¤©æ°”",
    "ä¼šä¸‹é›¨å—ï¼Ÿ",
    "é›¨å¤©å¼€è½¦è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ",
    "é«˜é€Ÿè·¯å†µæ€ä¹ˆæ ·ï¼Ÿ",
    "æœ‰å›¢é›¾é¢„è­¦å—ï¼Ÿ",
    "æ¨èä¸€æ¡æ›´å®‰å…¨çš„è·¯çº¿",
    "é¢„è®¡ä»€ä¹ˆæ—¶å€™å¤©æ°”è½¬å¥½ï¼Ÿ"
]

# åœºæ™¯26: è½¦è¾†ç»´æŠ¤åœºæ™¯ï¼ˆå”®åæœåŠ¡ï¼‰
vehicle_maintenance_scenario = [
    "æˆ‘çš„è½¦æ˜¯ç‰¹æ–¯æ‹‰",
    "æˆ‘çš„è½¦è¯¥ä¿å…»äº†ï¼Œé™„è¿‘æœ‰4Såº—å—ï¼Ÿ",
    "å“ªå®¶è¯„ä»·å¥½ï¼Ÿ",
    "è¥ä¸šæ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿ",
    "éœ€è¦é¢„çº¦å—ï¼Ÿ",
    "å¯¼èˆªè¿‡å»",
    "ä¿å…»å¤§æ¦‚éœ€è¦å¤šä¹…ï¼Ÿ",
    "ç­‰å¾…çš„æ—¶å€™é™„è¿‘æœ‰ä»€ä¹ˆåœ°æ–¹å¯ä»¥é€›ï¼Ÿ"
]

# åœºæ™¯27: æ–°æ‰‹å¸æœºåœºæ™¯ï¼ˆè¾…åŠ©é©¾é©¶ï¼‰
novice_driver_scenario = [
    "æˆ‘æ˜¯æ–°æ‰‹ï¼Œæƒ³å»é¢å’Œå›­ï¼Œå¸®æˆ‘è§„åˆ’ä¸€æ¡ç®€å•å¥½èµ°çš„è·¯çº¿",
    "é¿å¼€å¤æ‚è·¯å£å’Œç«‹äº¤æ¡¥",
    "è¿™æ¡è·¯çº¿æœ‰å‡ ä¸ªçº¢ç»¿ç¯ï¼Ÿ",
    "æœ‰æ²¡æœ‰éš¾èµ°çš„åœ°æ–¹ï¼Ÿ",
    "é‚£é‡Œå¥½åœè½¦å—ï¼Ÿ",
]

# åœºæ™¯28: å•†åŠ¡å‡ºè¡Œåœºæ™¯ï¼ˆæ•ˆç‡ä¼˜å…ˆï¼‰
business_trip_scenario = [
    "æˆ‘10ç‚¹æœ‰ä¸ªä¼šè®®åœ¨å›½è´¸ï¼Œç°åœ¨åœ¨é…’åº—",
    "æœ€å¿«å¤šä¹…èƒ½åˆ°ï¼Ÿ",
    "è§„åˆ’æœ€å¿«è·¯çº¿",
    "ä¼šè¿Ÿåˆ°å—ï¼Ÿ",
    "å¦‚æœæ‰“è½¦å‘¢ï¼Ÿ",
    "é™„è¿‘æœ‰åœ°é“å—ï¼Ÿå“ªä¸ªæ›´å¿«ï¼Ÿ",
]

# åœºæ™¯29: å®¶åº­å‡ºæ¸¸åœºæ™¯ï¼ˆèˆ’é€‚ä¼˜å…ˆï¼‰
family_trip_scenario = [
    "å¸¦ç€è€äººå’Œå­©å­å»åŠ¨ç‰©å›­ï¼Œå¸®æˆ‘è§„åˆ’ä¸€æ¡èˆ’é€‚çš„è·¯çº¿",
    "é¿å¼€é¢ ç°¸è·¯æ®µ",
    "è·¯ä¸Šæœ‰ä¼‘æ¯åŒºå—ï¼Ÿ",
    "é‚£é‡Œæœ‰æ¯å©´å®¤å—ï¼Ÿ",
    "åœè½¦åœºç¦»å…¥å£è¿‘å—ï¼Ÿ",
    "å›­åŒºé‡Œæœ‰è½®æ¤…ç§Ÿèµå—ï¼Ÿ",
    "ç©å®Œäº†æ¨èä¸€ä¸ªé€‚åˆå®¶åº­èšé¤çš„é¤å…"
]

# åœºæ™¯30: å¤œé—´é©¾é©¶åœºæ™¯ï¼ˆå®‰å…¨åœºæ™¯ï¼‰
night_driving_scenario = [
    "æ™šä¸Šè¦å¼€è½¦å›å®¶ï¼Œä»CBDåˆ°é€šå·",
    "å¤œé—´è¿™æ¡è·¯å®‰å…¨å—ï¼Ÿ",
    "è·¯ç¯ç…§æ˜å¥½å—ï¼Ÿ",
    "æœ‰æ²¡æœ‰æ›´æ˜äº®çš„è·¯çº¿ï¼Ÿ",
    "é€”ä¸­æœ‰24å°æ—¶ä¾¿åˆ©åº—å—ï¼Ÿ",
    "å¦‚æœå›°äº†ï¼Œé™„è¿‘æœ‰å®‰å…¨çš„ä¼‘æ¯åŒºå—ï¼Ÿ",
    "é¢„è®¡å‡ ç‚¹èƒ½åˆ°å®¶ï¼Ÿ"
]

# æ‰€æœ‰åœºæ™¯é›†åˆï¼ˆåªä¿ç•™åŸºç¡€åœºæ™¯å’Œæ™ºèƒ½åº§èˆ±ä¸“å±åœºæ™¯ï¼‰
all_scenarios = {
    "åŸºç¡€åœºæ™¯": test_questions,
    # æ™ºèƒ½åº§èˆ±ä¸“å±åœºæ™¯
    "ğŸš—æ™ºèƒ½å¯¼èˆª": smart_navigation_scenario,
    "ğŸš—æ²¿é€”æœåŠ¡": enroute_service_scenario,
    "ğŸš—åœè½¦åœºæ™¯": parking_scenario,
    "ğŸš—è‡ªé©¾æ¸¸": road_trip_scenario,
    "ğŸš—æ¥é€äºº": pickup_scenario,
    "ğŸš—å……ç”µåŠ æ²¹": refuel_scenario,
    "ğŸš—å®æ—¶è·¯å†µ": traffic_scenario,
    "ğŸš—å¤šç›®çš„åœ°": multi_destination_scenario,
    "ğŸš—å¤©æ°”è·¯å†µ": weather_driving_scenario,
    "ğŸš—è½¦è¾†ç»´æŠ¤": vehicle_maintenance_scenario,
    "ğŸš—æ–°æ‰‹å¸æœº": novice_driver_scenario,
    "ğŸš—å•†åŠ¡å‡ºè¡Œ": business_trip_scenario,
    "ğŸš—å®¶åº­å‡ºæ¸¸": family_trip_scenario,
    "ğŸš—å¤œé—´é©¾é©¶": night_driving_scenario
}

# æ™ºèƒ½åº§èˆ±æ¨èåœºæ™¯ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
in_car_recommended_scenarios = [
    "ğŸš—æ™ºèƒ½å¯¼èˆª",    # P0 - æ ¸å¿ƒåŠŸèƒ½
    "ğŸš—å®æ—¶è·¯å†µ",    # P0 - æ ¸å¿ƒåŠŸèƒ½
    "ğŸš—æ²¿é€”æœåŠ¡",    # P1 - é«˜é¢‘åœºæ™¯
    "ğŸš—åœè½¦åœºæ™¯",    # P1 - åˆšéœ€åœºæ™¯
    "ğŸš—å……ç”µåŠ æ²¹",    # P1 - åˆšéœ€åœºæ™¯
    "ğŸš—æ¥é€äºº",      # P2 - æ—¥å¸¸é«˜é¢‘
    "ğŸš—è‡ªé©¾æ¸¸",      # P2 - å‘¨æœ«åœºæ™¯
    "ğŸš—å¤šç›®çš„åœ°",    # P2 - å¤æ‚è§„åˆ’
    "ğŸš—è¯­éŸ³æ§åˆ¶",    # P2 - äº¤äº’æ–¹å¼
    "ğŸš—å¤©æ°”è·¯å†µ",    # P3 - å®‰å…¨è¾…åŠ©
    "ğŸš—è½¦è¾†ç»´æŠ¤",    # P3 - å”®åæœåŠ¡
    "ğŸš—å•†åŠ¡å‡ºè¡Œ",    # P3 - å•†åŠ¡åœºæ™¯
    "ğŸš—å®¶åº­å‡ºæ¸¸",    # P3 - å®¶åº­åœºæ™¯
    "ğŸš—æ–°æ‰‹å¸æœº",    # P3 - è¾…åŠ©é©¾é©¶
    "ğŸš—å¤œé—´é©¾é©¶",    # P3 - å¤œé—´å®‰å…¨
]

def invoke_agent(prompt: str, agent_runtime_arn: str, session_id: str = None, streaming: bool = True):
    """
    Invoke the AgentCore runtime with a prompt
    
    Args:
        prompt: User question/prompt
        agent_runtime_arn: ARN of the deployed AgentCore runtime
        session_id: Optional session ID (must be 33+ chars if provided)
        streaming: Whether to use streaming output (default: True)
    
    Returns:
        Agent response data (for non-streaming) or None (for streaming)
    """
    # Generate a default session ID if not provided
    if session_id is None:
        import uuid
        session_id = f"1111111111111111111111111111111111111"  # 41 characters
    
    # Prepare the payload
    # AgentCore expects the payload format to match the entrypoint function signature
    payload = json.dumps({
        "prompt": prompt
    }).encode()
    
    print(f"\n{'='*60}")
    print(f"Question: {prompt}")
    print(f"{'='*60}")
    
    try:
        # Invoke the agent
        response = agent_core_client.invoke_agent_runtime(
            agentRuntimeArn=agent_runtime_arn,
            runtimeSessionId=session_id,
            payload=payload,
            qualifier="DEFAULT"
        )
        
        # Check content type and handle accordingly
        content_type = response.get("contentType", "")
        
        if "text/event-stream" in content_type:
            # Handle streaming response
            print("\næµå¼å“åº”:")
            print("-" * 60)
            accumulated_text = []
            
            for line in response["response"].iter_lines(chunk_size=10):
                if line:
                    line = line.decode("utf-8")
                    if line.startswith("data: "):
                        data_str = line[6:]  # Remove "data: " prefix
                        
                        try:
                            data = json.loads(data_str)
                            
                            # åªæå–å’Œæ˜¾ç¤º contentBlockDelta ä¸­çš„æ–‡æœ¬
                            if isinstance(data, dict):
                                if 'event' in data and 'contentBlockDelta' in data['event']:
                                    delta = data['event']['contentBlockDelta'].get('delta', {})
                                    if 'text' in delta:
                                        text_chunk = delta['text']
                                        # å®æ—¶æ‰“å°æ–‡æœ¬å—
                                        print(text_chunk, end='', flush=True)
                                        accumulated_text.append(text_chunk)
                                elif 'error' in data:
                                    print(f"\né”™è¯¯: {data['error']}", flush=True)
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯ JSONï¼Œè·³è¿‡
                            pass
            
            print("\n" + "=" * 60)
            full_response = "".join(accumulated_text)
            print(f"å®Œæ•´å“åº” ({len(accumulated_text)} ä¸ªæ–‡æœ¬å—):")
            print(full_response)
            return full_response
            
        elif content_type == "application/json":
            # Handle standard JSON response
            content = []
            for chunk in response.get("response", []):
                content.append(chunk.decode('utf-8'))
            
            response_data = json.loads(''.join(content))
            print("Agent Response:", json.dumps(response_data, indent=2, ensure_ascii=False))
            return response_data
        
        else:
            # Handle other content types
            response_body = response['response'].read()
            print("Raw Response:", response_body.decode('utf-8'))
            return response_body.decode('utf-8')
        
    except Exception as e:
        print(f"Error invoking agent: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """
    Main function to test the AgentCore Baidu Map Agent with streaming output
    """
    # TODO: Replace with your actual AgentCore runtime ARN
    # You can get this ARN after deploying with: agentcore deploy
    agent_runtime_arn = 'arn:aws:bedrock-agentcore:us-west-2:741040131740:runtime/agentcore_baidu_map_agent-JWw0Aw8Cn1'
    
    # Generate a single session ID for all questions to maintain conversation context
    import uuid
    session_id = f"session_{uuid.uuid4().hex}"  # 41 characters
    
    print("AgentCore Baidu Map Agent - Boto3 Client (æµå¼è¾“å‡º)")
    print("=" * 80)
    print(f"Runtime ARN: {agent_runtime_arn}")
    print(f"Session ID: {session_id}")
    print("=" * 80)
    print("\næ³¨æ„: æ­¤å®¢æˆ·ç«¯ä½¿ç”¨æµå¼è¾“å‡ºï¼Œå“åº”å°†å®æ—¶æ˜¾ç¤º")
    print("æ³¨æ„: æ‰€æœ‰é—®é¢˜ä½¿ç”¨ç›¸åŒçš„ session ID ä»¥ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡")
    print("=" * 80)
    
    # Display available scenarios
    print("\nğŸš— æ™ºèƒ½åº§èˆ±å¯¹è¯åœºæ™¯ (å…±16ä¸ªåœºæ™¯):")
    print("=" * 80)
    
    # Separate basic and in-car scenarios
    basic_scenarios = {k: v for k, v in all_scenarios.items() if not k.startswith("ğŸš—")}
    car_scenarios = {k: v for k, v in all_scenarios.items() if k.startswith("ğŸš—")}
    
    print("\nåŸºç¡€åœºæ™¯:")
    print("-" * 80)
    for idx, scenario_name in enumerate(basic_scenarios.keys(), 1):
        scenario_questions = basic_scenarios[scenario_name]
        print(f"{idx:2d}. {scenario_name:12s} - {len(scenario_questions)} ä¸ªé—®é¢˜")
    
    print("\nğŸš— æ™ºèƒ½åº§èˆ±ä¸“å±åœºæ™¯ (æŒ‰ä¼˜å…ˆçº§æ’åº):")
    print("-" * 80)
    start_idx = len(basic_scenarios) + 1
    for idx, scenario_name in enumerate(car_scenarios.keys(), start_idx):
        scenario_questions = car_scenarios[scenario_name]
        priority = "P0" if scenario_name in ["ğŸš—æ™ºèƒ½å¯¼èˆª", "ğŸš—å®æ—¶è·¯å†µ"] else \
                   "P1" if scenario_name in ["ğŸš—æ²¿é€”æœåŠ¡", "ğŸš—åœè½¦åœºæ™¯", "ğŸš—å……ç”µåŠ æ²¹"] else \
                   "P2" if scenario_name in ["ğŸš—æ¥é€äºº", "ğŸš—è‡ªé©¾æ¸¸", "ğŸš—å¤šç›®çš„åœ°", "ğŸš—è¯­éŸ³æ§åˆ¶"] else "P3"
        print(f"{idx:2d}. {scenario_name:12s} - {len(scenario_questions)} ä¸ªé—®é¢˜ [{priority}]")
    
    print("=" * 80)
    print(f"{len(all_scenarios) + 1:2d}. å…¨éƒ¨åœºæ™¯     - è¿è¡Œæ‰€æœ‰åœºæ™¯ (åŸºç¡€ + åº§èˆ±)")
    print(f"{len(all_scenarios) + 2:2d}. åº§èˆ±æ¨¡å¼     - æŒ‰ä¼˜å…ˆçº§è¿è¡Œåº§èˆ±åœºæ™¯ (æ¨è)")
    print("=" * 80)
    
    # Let user choose a scenario
    try:
        choice = input("\nè¯·é€‰æ‹©åœºæ™¯ç¼–å· (ç›´æ¥å›è½¦è¿è¡ŒåŸºç¡€åœºæ™¯): ").strip()
        
        if not choice:
            # Default to basic scenario
            selected_scenario = "åŸºç¡€åœºæ™¯"
            questions = test_questions
        elif choice.isdigit():
            choice_num = int(choice)
            if choice_num == len(all_scenarios) + 1:
                # Run all scenarios
                print("\nå°†è¿è¡Œæ‰€æœ‰åœºæ™¯...")
                for scenario_name, questions in all_scenarios.items():
                    print(f"\n\n{'='*80}")
                    print(f"åœºæ™¯: {scenario_name}")
                    print(f"{'='*80}")
                    run_scenario(questions, agent_runtime_arn, session_id, scenario_name)
                    
                    if scenario_name != list(all_scenarios.keys())[-1]:
                        cont = input("\nç»§ç»­ä¸‹ä¸€ä¸ªåœºæ™¯? (y/n): ").strip().lower()
                        if cont != 'y':
                            break
                print("\n\næ‰€æœ‰åœºæ™¯æµ‹è¯•å®Œæˆ!")
                return
            elif choice_num == len(all_scenarios) + 2:
                # Run in-car scenarios only
                print("\nğŸš— æ™ºèƒ½åº§èˆ±æ¨¡å¼ - è¿è¡Œæ¨èåœºæ™¯...")
                print("=" * 80)
                for scenario_name in in_car_recommended_scenarios:
                    if scenario_name in all_scenarios:
                        questions = all_scenarios[scenario_name]
                        print(f"\n\n{'='*80}")
                        print(f"ğŸš— åœºæ™¯: {scenario_name}")
                        print(f"{'='*80}")
                        run_scenario(questions, agent_runtime_arn, session_id, scenario_name)
                        
                        if scenario_name != in_car_recommended_scenarios[-1]:
                            cont = input("\nç»§ç»­ä¸‹ä¸€ä¸ªåœºæ™¯? (y/n): ").strip().lower()
                            if cont != 'y':
                                break
                print("\n\nğŸš— æ™ºèƒ½åº§èˆ±åœºæ™¯æµ‹è¯•å®Œæˆ!")
                return
            elif 1 <= choice_num <= len(all_scenarios):
                selected_scenario = list(all_scenarios.keys())[choice_num - 1]
                questions = all_scenarios[selected_scenario]
            else:
                print("æ— æ•ˆçš„é€‰æ‹©ï¼Œä½¿ç”¨åŸºç¡€åœºæ™¯")
                selected_scenario = "åŸºç¡€åœºæ™¯"
                questions = test_questions
        else:
            print("æ— æ•ˆçš„è¾“å…¥ï¼Œä½¿ç”¨åŸºç¡€åœºæ™¯")
            selected_scenario = "åŸºç¡€åœºæ™¯"
            questions = test_questions
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·å–æ¶ˆ")
        return
    
    print(f"\n\n{'='*80}")
    print(f"è¿è¡Œåœºæ™¯: {selected_scenario}")
    print(f"{'='*80}")
    
    run_scenario(questions, agent_runtime_arn, session_id, selected_scenario)
    
    print("\n\nåœºæ™¯æµ‹è¯•å®Œæˆ!")


def run_scenario(questions, agent_runtime_arn, session_id, scenario_name):
    """
    Run a specific scenario with a list of questions
    
    Args:
        questions: List of questions to ask
        agent_runtime_arn: ARN of the deployed AgentCore runtime
        session_id: Session ID for conversation context
        scenario_name: Name of the scenario for display
    """
    for i, question in enumerate(questions, 1):
        print(f"\n\n[{scenario_name}] é—®é¢˜ {i}/{len(questions)}")
        invoke_agent(
            prompt=question,
            agent_runtime_arn=agent_runtime_arn,
            session_id=session_id,
            streaming=True
        )
        
        # Optional: pause between requests
        if i < len(questions):
            try:
                input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªé—®é¢˜ (Ctrl+C é€€å‡º)...")
            except KeyboardInterrupt:
                print("\n\nç”¨æˆ·ä¸­æ–­åœºæ™¯")
                break


if __name__ == "__main__":
    # You can also test with a single custom question
    import sys
    
    if len(sys.argv) > 1:
        # Custom question from command line
        custom_question = " ".join(sys.argv[1:])
        agent_runtime_arn = 'arn:aws:bedrock-agentcore:us-west-2:741040131740:runtime/agentcore_baidu_map_agent-JWw0Aw8Cn1'
        invoke_agent(custom_question, agent_runtime_arn, streaming=True)
    else:
        # Run all test questions
        main()
